# Maximum number of documents to retrieve for a document set
max_documents=2000000
max_documents=${?OV_MAX_DOCUMENTS}

# Where Overview stores its (Lucene, for now) search indexes
search {
  baseDirectory: "search"
  baseDirectory: ${?OV_SEARCH_DIRECTORY}
}

# Maximum memory for each clustering.
# This will be a `java` "-Xmx" setting: e.g., "2000m"
clustering_memory=2500m
clustering_memory=${?OV_CLUSTERING_MEMORY}

ingest {
  # Number of documents to convert to PDF at once.
  #
  # Converting documents takes 100% CPU, so don't set this higher than the
  # number of CPUs.
  #
  # TODO nix this, as we migrate to the http broker
  n_document_converters=2
  n_document_converters=${?OV_N_DOCUMENT_CONVERTERS}

  # Address of HTTP work broker
  #
  # Conversion workers will connect to this address to download tasks and
  # upload results.
  broker_http_address=0.0.0.0

  # Port of HTTP work broker
  broker_http_port=9032

  # How long a worker can go without sending messages before we deem it to
  # be stalled.
  #
  # This can be quite short: slow workers can simply send "0%" progress messages
  # or keep an HTTP POST connection open to keep the task alive.
  #worker_idle_timeout=60s
  worker_idle_timeout=15s

  # Maximum allowed number of converters per file type
  #
  # HTTP converters are cheap on the server side. The limit can detect bugs,
  # though, as it will cause Overview to crash if a broken worker causes
  # denial of service by hoarding all the work to itself and never completing
  # it.
  max_n_http_workers_per_step=10
  max_n_http_workers_per_step=${?OV_MAX_N_HTTP_WORKERS_PER_STEP}

  # How long the worker should long-poll for a new task.
  #
  # We _enforce_ long-polling. If the client disconnects and then the long poll
  # completes with a task, the server will think it sent that task to the client
  # -- meaning other clients won't see it until the timeout.
  #
  # Set this long enough that we don't get pounded with HTTP requests and short
  # enough that clients don't disconnect on their own.
  worker_http_create_timeout=15s

  # How many files we allow a converter to output and feed back as input into
  # another converter. The canonically-dangerous step is a zipfile full of
  # zipfiles: if the recurse buffer isn't large enough, the ingest pipeline
  # will stall.
  #
  # A file consumes about as much data as its metadata JSON: assume 5kb/doc.
  max_recurse_buffer_length=10000

  # How many documents and errors to create at once when ingesting converted
  # files.
  #
  # A larger batch means fewer SQL commands, but the transaction takes longer.
  batch_size=100

  # How long to spend batching documents for ingesting.
  #
  # A slow timeout leads to bigger batches (up to a maximum of batch_size), but
  # on average the entire file import will wait (batch_max_wait/2) after the
  # last conversion has finished.
  batch_max_wait=200ms
}

# Maximum memory for each PDF processing step. (They may be concurrent.)
#
# This will be a `java` "-Xmx" setting: e.g., "1000m"
#
# This doesn't include the memory used by Tesseract. Assume that's ~100mb tops.
pdf_memory=1400m
pdf_memory=${?OV_PDF_MEMORY}

# maximum number of UTF-16 characters in a single document. Overview isn't
# designed to handle massive string sizes; if this value is too high, you may
# see an OutOfMemoryError when we fetch and tokenize 20 documents from the
# database.
max_n_chars_per_document=655360 # ought to be enough for anybody ;)

# Path to tesseract binary (eg. /usr/local/bin/tesseract)
# Set via environment variable TESSERACT_PATH or add the appropriate value to the PATH
tesseract_path=tesseract
tesseract_path=${?OV_TESSERACT_PATH}

# Clustering algorithm to use. One of:
#  KMeans
#  ConnectedComponents
#  KMeansComponents <- default
clustering_alg = KMeansComponents

# Maximum token length to cluster
#
# Any token above this number of characters (not Unicode codepoints) will
# be discarded before we begin clustering.
max_clustering_token_length=40
max_clustering_token_length=${?OV_MAX_CLUSTERING_TOKEN_LENGTH}

# Maximum memory to spend when sorting documents by metadata field values.
# This is _multiplied_ by the number of concurrent sorts.
max_mb_per_sort=200
max_mb_per_sort=${?OV_MAX_MB_PER_SORT}
n_concurrent_sorts=2
n_concurrent_sorts=${?OV_N_CONCURRENT_SORTS}

akka {
  jvm-exit-on-fatal-error: on

  actor {
    provider: "akka.remote.RemoteActorRefProvider"
    guardian-supervisor-strategy: "com.overviewdocs.akkautil.FailFastSupervisorStrategyConfigurator"
  }

  remote {
    enabled-transports: [ "akka.remote.netty.tcp" ]
    retry-gate-closed-for: 1s

    netty.tcp {
      hostname: "localhost"
      hostname: ${?MESSAGE_BROKER_HOSTNAME}
      bind-hostname: "localhost"
      bind-hostname: ${?MESSAGE_BROKER_HOSTNAME}
      bind-hostname: ${?MESSAGE_BROKER_BIND_HOSTNAME}
      port: 9030
      port: ${?MESSAGE_BROKER_PORT}
    }
  }
}

# http://doc.akka.io/docs/akka/snapshot/scala/dispatchers.html
blocking-io-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 8
  }
  throughput = 1
}
